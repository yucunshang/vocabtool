import streamlit as st
import pandas as pd
import re

st.set_page_config(page_title="Vibe Vocab Studio", page_icon="âš¡", layout="wide")

# --- æ ¸å¿ƒé€»è¾‘ï¼šä¸ä¾èµ– AIï¼Œçº¯ç®—æ³•æé€Ÿå¤„ç† ---

def get_sentence_context(text, word):
    """ç”¨æ­£åˆ™æŸ¥æ‰¾åŒ…å«å•è¯çš„å¥å­ (æ›¿ä»£ Spacy)"""
    # ç®€å•çš„åˆ†å¥é€»è¾‘ï¼šæŒ‰ . ! ? åˆ†å‰²
    sentences = re.split(r'(?<=[.!?])\s+', text)
    for sent in sentences:
        # å¦‚æœå•è¯(ä½œä¸ºç‹¬ç«‹è¯)åœ¨å¥å­é‡Œ
        if re.search(r'\b' + re.escape(word) + r'\b', sent, re.IGNORECASE):
            return sent.strip()[:300] # é™åˆ¶é•¿åº¦é˜²æ­¢å¤ªé•¿
    return "æœªæ‰¾åˆ°åŸå¥"

def process_text_lite(text, vocab_df, user_limit):
    # 1. æ¸…æ´—ä¸æå–
    text_lower = text.lower()
    
    # æ­£åˆ™æå–æ‰€æœ‰å•è¯ (é•¿åº¦>2, çº¯å­—æ¯)
    words = re.findall(r'\b[a-z]{2,}\b', text_lower)
    unique_words = sorted(list(set(words)))
    
    found_items = []
    
    # 2. å»ºç«‹é«˜é€ŸæŸ¥è¯¢å­—å…¸
    # ç¡®ä¿åˆ—åå°å†™
    vocab_df.columns = [c.lower() for c in vocab_df.columns]
    # word -> rank å­—å…¸
    if 'word' in vocab_df.columns and 'rank' in vocab_df.columns:
        # è½¬ä¸ºå­—å…¸åŠ é€Ÿ
        vocab_dict = pd.Series(vocab_df['rank'].values, index=vocab_df['word'].astype(str)).to_dict()
    else:
        st.error("âŒ è¯åº“å¿…é¡»åŒ…å« 'word' å’Œ 'rank' ä¸¤åˆ—ï¼")
        return pd.DataFrame(), pd.DataFrame()

    # 3. åŒ¹é…ä¸åˆ†çº§
    for w in unique_words:
        rank = 999999
        match_word = w
        
        # ç²¾ç¡®åŒ¹é…
        if w in vocab_dict:
            rank = vocab_dict[w]
        # ç®€å•è¿˜åŸè§„åˆ™ (å»s, ed, ing)
        elif w.endswith('s') and w[:-1] in vocab_dict:
            match_word = w[:-1]
            rank = vocab_dict[match_word]
        elif w.endswith('ed') and w[:-2] in vocab_dict:
            match_word = w[:-2]
            rank = vocab_dict[match_word]
        elif w.endswith('ing') and w[:-3] in vocab_dict:
            match_word = w[:-3]
            rank = vocab_dict[match_word]
            
        # 4. æå–åŸå¥ (é’ˆå¯¹ç”Ÿè¯)
        context = ""
        is_unknown = rank > user_limit
        if is_unknown:
            context = get_sentence_context(text, w)
            
        found_items.append({
            'word': match_word,
            'rank': rank,
            'is_known': not is_unknown,
            'context': context
        })

    # è½¬ DataFrame
    df = pd.DataFrame(found_items)
    if not df.empty:
        known = df[df['is_known']].sort_values('rank')
        unknown = df[~df['is_known']].sort_values('rank')
        return unknown, known
    return pd.DataFrame(), pd.DataFrame()


# --- ç•Œé¢ UI ---
st.title("âš¡ Vibe Vocab Studio (è½»é‡ç‰ˆ)")
st.markdown("### æé€Ÿè¯æ±‡åˆ†æ & Anki åˆ¶å¡å™¨")

# ä¾§è¾¹æ 
st.sidebar.header("ğŸ› ï¸ è®¾ç½®")
vocab_file = st.sidebar.file_uploader("1. ä¸Šä¼ è¯é¢‘è¡¨ (CSV/Excel)", type=['csv', 'xlsx'])
user_vocab = st.sidebar.slider("2. è¯æ±‡é‡é˜ˆå€¼", 1000, 20000, 6000, 500)

# è¾“å…¥åŒº
with st.expander("ğŸ“ æ–‡æœ¬è¾“å…¥ (æ”¯æŒé•¿æ–‡æœ¬)", expanded=True):
    tab1, tab2 = st.tabs(["ç²˜è´´æ–‡æœ¬", "ä¸Šä¼ æ–‡ä»¶"])
    with tab1:
        text_input_raw = st.text_area("åœ¨æ­¤ç²˜è´´:", height=150)
    with tab2:
        uploaded_txt = st.file_uploader("ä¸Šä¼  .txt å°è¯´/æ–‡ç« ", type="txt")
        if uploaded_txt:
            text_input_raw = uploaded_txt.read().decode("utf-8")

# åˆ†æé€»è¾‘
final_text = text_input_raw if text_input_raw else ""

if st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary"):
    if not vocab_file:
        st.error("è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼ è¯åº“æ–‡ä»¶ï¼")
    elif not final_text.strip():
        st.warning("è¯·è¾“å…¥æ–‡æœ¬å†…å®¹ï¼")
    else:
        try:
            # è¯»å–è¯åº“
            if vocab_file.name.endswith('.csv'):
                vocab_df = pd.read_csv(vocab_file)
            else:
                vocab_df = pd.read_excel(vocab_file)
            
            with st.spinner("æ­£åœ¨æé€Ÿåˆ†æ..."):
                unknown_df, known_df = process_text_lite(final_text, vocab_df, user_vocab)
            
            st.success(f"åˆ†æå®Œæˆï¼å‘ç° {len(unknown_df)} ä¸ªç”Ÿè¯ã€‚")
            
            # --- ç»“æœå±•ç¤º ---
            res_tab1, res_tab2, res_tab3 = st.tabs(["ğŸ”´ ç”Ÿè¯è¡¨", "ğŸŸ¢ ç†Ÿè¯è¡¨", "ğŸ´ Anki åˆ¶å¡"])
            
            with res_tab1:
                st.dataframe(unknown_df[['word', 'rank', 'context']], use_container_width=True)
                # ç®€å•å¯¼å‡º
                csv = unknown_df.to_csv(index=False).encode('utf-8')
                st.download_button("ğŸ“¥ ä¸‹è½½ç”Ÿè¯è¡¨ (CSV)", csv, "unknown.csv", "text/csv")

            with res_tab2:
                st.dataframe(known_df[['word', 'rank']], use_container_width=True)

            with res_tab3:
                st.markdown("#### Anki å¯¼å…¥æ–‡ä»¶ç”Ÿæˆ")
                st.info("å·²è‡ªåŠ¨ä¸ºä½ æå–äº†ç”Ÿè¯æ‰€åœ¨çš„ã€åŸå¥ã€‘ã€‚")
                
                # Anki å¯¼å‡ºé€»è¾‘
                anki_df = pd.DataFrame()
                anki_df['Front'] = unknown_df['word']
                # èƒŒé¢ï¼šåŸå¥ + <br> + æ’å
                anki_df['Back'] = unknown_df['context'] + "<br><br>Rank: #" + unknown_df['rank'].astype(str)
                
                st.write("é¢„è§ˆ (å‰5æ¡):")
                st.table(anki_df.head())
                
                anki_csv = anki_df.to_csv(index=False, header=False).encode('utf-8')
                st.download_button(
                    "âš¡ ä¸‹è½½ Anki å¯¼å…¥åŒ… (.csv)", 
                    anki_csv, 
                    "anki_import.csv", 
                    "text/csv",
                    help="ç›´æ¥å¯¼å…¥ Anki å³å¯ï¼Œæ­£é¢æ˜¯å•è¯ï¼ŒèƒŒé¢æ˜¯åŸå¥å’Œæ’å"
                )

        except Exception as e:
            st.error(f"å‘ç”Ÿé”™è¯¯: {e}")