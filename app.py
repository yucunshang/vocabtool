import streamlit as st
import pandas as pd
import re
import os
import simplemma

st.set_page_config(page_title="Vibe Vocab Studio", page_icon="ğŸ", layout="wide")

# ==========================================
# ğŸ v6.0 æ ¸å¿ƒä¿®å¤ä¸è¯Šæ–­æ¨¡å—
# ==========================================

# 1. å¼ºåŠ› Simplemma åŠ è½½ (å¸¦è‡ªæˆ‘æ£€æµ‹)
LEMMA_STATUS = "æœªçŸ¥"
try:
    # å°è¯•æ–°ç‰ˆ (v1.0+)
    test = simplemma.lemmatize("went", lang="en")
    def get_lemma(word): return simplemma.lemmatize(word, lang="en")
    if test == "go": 
        LEMMA_STATUS = "âœ… æ­£å¸¸ (v1.x)"
    else:
        LEMMA_STATUS = f"âš ï¸ å¼‚å¸¸ (è¿”å›: {test})"
except TypeError:
    # å°è¯•æ—§ç‰ˆ
    try:
        lang_data = simplemma.load_data('en')
        def get_lemma(word): return simplemma.lemmatize(word, lang_data)
        if get_lemma("went") == "go":
            LEMMA_STATUS = "âœ… æ­£å¸¸ (v0.9)"
        else:
            LEMMA_STATUS = "âš ï¸ å¼‚å¸¸ (æ—§ç‰ˆåŠ è½½å¤±è´¥)"
    except:
        def get_lemma(word): return word
        LEMMA_STATUS = "âŒ å¤±è´¥ (æ— æ³•åŠ è½½åº“)"

# 2. å¼ºåŠ›è¯åº“åŠ è½½ (æŒ‡å®šåˆ—åè¯»å–)
POSSIBLE_FILES = ["coca_cleaned.csv", "data.csv", "COCA20000è¯Excelç‰ˆ.xlsx - Sheet1.csv"]

@st.cache_data
def load_vocab_debug():
    file_path = None
    for f in POSSIBLE_FILES:
        if os.path.exists(f):
            file_path = f
            break
    
    if not file_path: return None, "æœªæ‰¾åˆ°ä»»ä½• csv æ–‡ä»¶", {}

    try:
        df = None
        # ä¸“é—¨é’ˆå¯¹ coca_cleaned.csv çš„ä¼˜åŒ–è¯»å–
        if "cleaned" in file_path:
            # æ—¢ç„¶æ˜¯ cleanedï¼Œæˆ‘ä»¬å‡å®šå®ƒæ²¡æœ‰è¡¨å¤´ï¼Œæˆ–è€…è¡¨å¤´æ˜¯æ ‡å‡†è‹±æ–‡
            # å°è¯•ç›´æ¥æŒ‡å®šåˆ—åè¯»å–ï¼Œå¼ºåˆ¶ä¿®å¤
            try:
                # å°è¯•å½“ä½œæ— è¡¨å¤´è¯»å–
                df_test = pd.read_csv(file_path, header=None)
                # æ£€æŸ¥ç¬¬ä¸€è¡Œæ˜¯ä¸æ˜¯ word, rank
                first_cell = str(df_test.iloc[0,0])
                if 'word' in first_cell.lower():
                     # æœ‰è¡¨å¤´
                     df = pd.read_csv(file_path)
                else:
                     # æ— è¡¨å¤´ï¼Œæ‰‹åŠ¨æŒ‡å®š
                     df = pd.read_csv(file_path, header=None, names=['word', 'rank'])
            except:
                pass

        # å¦‚æœä¸Šé¢çš„ä¸“ç”¨è¯»å–æ²¡è·‘é€šï¼Œèµ°é€šç”¨è¯»å–
        if df is None:
            for enc in ['utf-8-sig', 'utf-8', 'gbk']:
                try:
                    df = pd.read_csv(file_path, encoding=enc)
                    if len(df) > 10: break
                except: continue

        if df is None: return None, "æ–‡ä»¶è¯»å–å¤±è´¥ (ç¼–ç é”™è¯¯?)", {}

        # ç»Ÿä¸€åˆ—å
        df.columns = [str(c).strip().lower() for c in df.columns]
        cols = list(df.columns)

        # å¯»æ‰¾ word å’Œ rank
        w_col, r_col = None, None
        
        # ç­–ç•¥1: ç²¾ç¡®åŒ¹é…
        if 'word' in cols and 'rank' in cols:
            w_col, r_col = 'word', 'rank'
        # ç­–ç•¥2: ä½ç½®çŒœæµ‹ (é’ˆå¯¹ coca_cleaned)
        elif len(cols) == 2:
            w_col, r_col = df.columns[0], df.columns[1]
        # ç­–ç•¥3: åŸå§‹æ–‡ä»¶çŒœæµ‹
        elif len(cols) >= 4:
            w_col, r_col = df.columns[0], df.columns[3]
        
        # ç­–ç•¥4: å…³é”®è¯æœç´¢
        if not w_col: w_col = next((c for c in df.columns if 'word' in c or 'å•è¯' in c), None)
        if not r_col: r_col = next((c for c in df.columns if 'rank' in c or 'æ’åº' in c or 'è¯é¢‘' in c), None)

        if not w_col or not r_col:
            return df, f"åˆ—åè¯†åˆ«å¤±è´¥: {cols}", {}

        # æå–æ•°æ®
        df['word_clean'] = df[w_col].astype(str).str.lower().str.strip()
        df['rank_clean'] = pd.to_numeric(df[r_col], errors='coerce').fillna(99999)
        
        # è¿‡æ»¤
        df = df[df['rank_clean'] > 0]
        df = df[df['rank_clean'] < 99999]
        
        vocab_dict = pd.Series(df['rank_clean'].values, index=df['word_clean']).to_dict()
        
        # è¯Šæ–­ä¿¡æ¯
        debug_info = {
            "file": file_path,
            "cols": cols,
            "used_cols": (w_col, r_col),
            "sample_the": vocab_dict.get('the', 'æœªæ‰¾åˆ°'),
            "sample_good": vocab_dict.get('good', 'æœªæ‰¾åˆ°'),
            "count": len(vocab_dict)
        }
        
        return df, "æˆåŠŸ", vocab_dict

    except Exception as e:
        return None, str(e), {}

# åŠ è½½æ•°æ®
df_raw, status, vocab_dict = load_vocab_debug()

# ==========================================
# ğŸ” ä¾§è¾¹æ ï¼šè¯Šæ–­é¢æ¿ (Debug Panel)
# ==========================================
st.sidebar.title("ğŸ› ï¸ è¯Šæ–­é¢æ¿")
st.sidebar.info("å¦‚æœç»“æœä¸å¯¹ï¼Œè¯·æˆªå›¾è¿™é‡Œå‘ç»™æˆ‘ï¼")

with st.sidebar.expander("1. è¿˜åŸå¼•æ“æ£€æµ‹", expanded=True):
    st.write(f"çŠ¶æ€: {LEMMA_STATUS}")
    st.caption("æµ‹è¯•: went -> " + get_lemma("went"))

with st.sidebar.expander("2. è¯åº“è¯»å–æ£€æµ‹", expanded=True):
    if vocab_dict:
        debug = load_vocab_debug()[2] # é‡æ–°è·å–debug info
        st.write(f"ğŸ“‚ æ–‡ä»¶: `{debug['file']}`")
        st.write(f"ğŸ”¢ æ€»è¯æ•°: `{debug['count']}`")
        
        st.markdown("---")
        st.write("**å…³é”®è¯æ’åæ£€æŸ¥:**")
        
        # æ£€æŸ¥ 'the'
        rank_the = debug['sample_the']
        icon_the = "âœ…" if rank_the == 1 else "âŒ"
        st.write(f"ğŸ”¹ 'the': {rank_the} {icon_the}")
        
        # æ£€æŸ¥ 'good'
        rank_good = debug['sample_good']
        st.write(f"ğŸ”¹ 'good': {rank_good}")
        
        if rank_the == 'æœªæ‰¾åˆ°' or rank_the > 100:
            st.error("ğŸš¨ ä¸¥é‡é”™è¯¯ï¼šåŸºç¡€è¯æ’åä¸å¯¹ï¼ä¸€å®šæ˜¯åˆ—è¯»å–é”™äº†ã€‚")
    else:
        st.error(f"åŠ è½½å¤±è´¥: {status}")

# ==========================================
# ä¸»ç¨‹åºé€»è¾‘
# ==========================================

st.sidebar.divider()
st.sidebar.subheader("å­¦ä¹ è®¾ç½®")
vocab_range = st.sidebar.slider("é€‰æ‹©åŒºé—´", 1, 20000, (6000, 8000), 500)
range_start, range_end = vocab_range

st.title("ğŸ Vibe Vocab v6.0 (è¯Šæ–­ç‰ˆ)")

if not vocab_dict:
    st.warning("âš ï¸ è¯·å…ˆè§£å†³å·¦ä¾§çš„æŠ¥é”™")
    st.stop()

def process_text_debug(text, vocab_dict, r_start, r_end):
    text_lower = text.lower()
    words = re.findall(r'\b[a-z\']{2,}\b', text_lower)
    unique_words = sorted(list(set(words)))
    
    known, target, beyond = [], [], []
    
    for w in unique_words:
        rank = 99999
        match = w
        
        # 1. æŸ¥åŸå½¢
        if w in vocab_dict:
            rank = vocab_dict[w]
        else:
            # 2. æŸ¥è¿˜åŸ
            lemma = get_lemma(w)
            if lemma in vocab_dict:
                rank = vocab_dict[lemma]
                match = lemma
            else:
                # 3. æŸ¥å˜ä½“
                if w.endswith("'s") and w[:-2] in vocab_dict:
                    rank = vocab_dict[w[:-2]]
                    match = w[:-2]

        item = {'å•è¯': match, 'åŸæ–‡': w, 'æ’å': int(rank)}
        
        if rank <= r_start: known.append(item)
        elif r_start < rank <= r_end: target.append(item)
        else:
            if match == w: item['åŸæ–‡'] = '-'
            beyond.append(item)
            
    return pd.DataFrame(known), pd.DataFrame(target), pd.DataFrame(beyond)

# è¾“å…¥åŒº
text_input = st.text_area("åœ¨æ­¤ç²˜è´´æ–‡æœ¬:", height=150)

if st.button("ğŸš€ å¼€å§‹åˆ†æ"):
    if not text_input.strip():
        st.warning("è¯·è¾“å…¥æ–‡æœ¬")
    else:
        df_k, df_t, df_b = process_text_debug(text_input, vocab_dict, range_start, range_end)
        
        st.success("åˆ†æå®Œæˆ")
        t1, t2, t3 = st.tabs([
            f"ğŸŸ¡ é‡ç‚¹ ({len(df_t)})", 
            f"ğŸ”´ è¶…çº² ({len(df_b)})", 
            f"ğŸŸ¢ ç†Ÿè¯ ({len(df_k)})"
        ])
        
        with t1: st.dataframe(df_t, use_container_width=True)
        with t2: st.dataframe(df_b, use_container_width=True)
        with t3: st.dataframe(df_k, use_container_width=True)