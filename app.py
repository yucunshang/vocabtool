import streamlit as st
import pandas as pd
import re
import os
import simplemma

# ==========================================
# 0. æ ¸å¿ƒä¿®å¤ï¼šå¼ºåˆ¶å†…ç½®æ˜ å°„è¡¨ (ä¸å†ä¾èµ–ä¸‹è½½)
# ==========================================
# è¿™é‡Œæ‰‹åŠ¨å®šä¹‰æœ€å¸¸è§çš„ä¸è§„åˆ™åŠ¨è¯ï¼Œç¡®ä¿ 100% èƒ½è¿˜åŸ
# å³ä½¿ simplemma æŒ‚äº†ï¼Œè¿™äº›è¯ä¹Ÿèƒ½å¯¹ï¼
MANUAL_LEMMAS = {
    "is": "be", "am": "be", "are": "be", "was": "be", "were": "be", 
    "been": "be", "being": "be", "'s": "be", "'re": "be", "'m": "be",
    "has": "have", "had": "have", "having": "have", "'ve": "have",
    "does": "do", "did": "do", "done": "do", "doing": "do",
    "went": "go", "gone": "go", "going": "go", "goes": "go",
    "made": "make", "making": "make", "makes": "make",
    "took": "take", "taken": "take", "taking": "take",
    "came": "come", "coming": "come",
    "saw": "see", "seen": "see",
    "knew": "know", "known": "know",
    "got": "get", "gotten": "get",
    "gave": "give", "given": "give",
    "told": "tell",
    "felt": "feel",
    "became": "become",
    "left": "leave",
    "put": "put",
    "meant": "mean",
    "kept": "keep",
    "let": "let",
    "began": "begin", "begun": "begin",
    "seemed": "seem",
    "helped": "help",
    "showed": "show",
    "heard": "hear",
    "played": "play",
    "ran": "run",
    "moved": "move",
    "lived": "live",
    "believed": "believe",
    "brought": "bring",
    "happened": "happen",
    "wrote": "write", "written": "write",
    "provided": "provide",
    "sat": "sit",
    "stood": "stand",
    "lost": "lose",
    "paid": "pay",
    "met": "meet",
    "included": "include",
    "continued": "continue",
    "set": "set",
    "learnt": "learn", "learned": "learn",
    "changed": "change",
    "led": "lead",
    "understood": "understand",
    "watched": "watch",
    "followed": "follow",
    "stopped": "stop",
    "created": "create",
    "spoke": "speak", "spoken": "speak",
    "read": "read",
    "allowed": "allow",
    "added": "add",
    "spent": "spend",
    "grew": "grow",
    "opened": "open",
    "walked": "walk",
    "won": "win",
    "offered": "offer",
    "remembered": "remember",
    "loved": "love",
    "considered": "consider",
    "appeared": "appear",
    "bought": "buy",
    "waited": "wait",
    "served": "serve",
    "died": "die",
    "sent": "send",
    "expected": "expect",
    "built": "build",
    "stayed": "stay",
    "fell": "fall", "fallen": "fall",
    "cut": "cut",
    "reached": "reach",
    "killed": "kill",
    "remained": "remain"
}

def get_lemma_robust(word):
    """ä¸‰ä¿é™©è¿˜åŸç­–ç•¥"""
    # 1. ç¬¬ä¸€å±‚ä¿é™©ï¼šæŸ¥æ‰‹åŠ¨è¡¨ (å¤„ç†æœ€é«˜é¢‘çš„ä¸è§„åˆ™è¯)
    if word in MANUAL_LEMMAS:
        return MANUAL_LEMMAS[word]
    
    # 2. ç¬¬äºŒå±‚ä¿é™©ï¼šSimplemma (å°è¯•è°ƒç”¨)
    try:
        res = simplemma.lemmatize(word, lang='en')
        if res != word: return res
    except:
        pass
        
    # 3. ç¬¬ä¸‰å±‚ä¿é™©ï¼šç®€å•è§„åˆ™å»å°¾ (å¤„ç†è§„åˆ™å¤æ•°/åŠ¨è¯)
    if word.endswith('s') and not word.endswith('ss'):
        return word[:-1]
    if word.endswith('ed'):
        return word[:-2]
    if word.endswith('ing'):
        return word[:-3]
    if word.endswith('ly'):
        return word[:-2]
        
    return word

# ==========================================
# 1. é¡µé¢é…ç½®
# ==========================================
st.set_page_config(page_title="Vibe Vocab Studio", page_icon="âš¡", layout="wide")
st.title("âš¡ Vibe Vocab v9.0 (ç¡¬æ ¸è¿˜åŸç‰ˆ)")
st.caption("å†…ç½®é«˜é¢‘å˜å½¢è¡¨ Â· ä¸“æ²» 'are/been' ä¸è®¤è¯†")

# ==========================================
# 2. è¯»å–è¯åº“
# ==========================================
POSSIBLE_FILES = ["coca_cleaned.csv", "data.csv", "COCA20000è¯Excelç‰ˆ.xlsx - Sheet1.csv"]

@st.cache_data
def load_vocab_simple():
    file_path = None
    for f in POSSIBLE_FILES:
        if os.path.exists(f):
            file_path = f
            break
            
    if not file_path: return None, "æœªæ‰¾åˆ°æ–‡ä»¶"

    # ä¼˜å…ˆè¯» coca_cleaned
    if 'cleaned' in file_path:
        try:
            df = pd.read_csv(file_path)
            # ç¡®ä¿åˆ—åæ­£ç¡®
            if 'word' in df.columns and 'rank' in df.columns:
                vocab = pd.Series(df['rank'].values, index=df['word'].astype(str)).to_dict()
                return vocab, "åŠ è½½æˆåŠŸ (Cleaned)"
        except: pass

    # å…œåº•è¯»åŸå§‹æ–‡ä»¶
    for enc in ['utf-8', 'utf-8-sig', 'gbk']:
        try:
            df = pd.read_csv(file_path, encoding=enc)
            # æ‰¾åˆ—
            cols = [str(c).lower() for c in df.columns]
            df.columns = cols
            
            w_col = next((c for c in cols if 'word' in c or 'å•è¯' in c), cols[0])
            r_col = next((c for c in cols if 'rank' in c or 'æ’åº' in c or 'è¯é¢‘' in c), cols[1] if len(cols)>1 else cols[0])
            
            # æ¸…æ´—
            df['w'] = df[w_col].astype(str).str.lower().str.strip()
            df['r'] = pd.to_numeric(df[r_col], errors='coerce').fillna(99999)
            
            vocab = pd.Series(df['r'].values, index=df['w']).to_dict()
            return vocab, "åŠ è½½æˆåŠŸ (Raw)"
        except: continue
        
    return None, "åŠ è½½å¤±è´¥"

vocab_dict, msg = load_vocab_simple()

if not vocab_dict:
    st.error(msg)
    st.stop()
    
# ä¾§è¾¹æ è‡ªæ£€
st.sidebar.success(f"ğŸ“š {msg}")
check_are = vocab_dict.get('be', 'Not Found')
st.sidebar.info(f"æ£€æŸ¥ç‚¹: 'be' æ’å = {check_are}")
st.sidebar.info(f"è¿˜åŸæµ‹è¯•: went -> {get_lemma_robust('went')}")

# ==========================================
# 3. æ ¸å¿ƒé€»è¾‘ (è°ƒç”¨å¼ºåŠ›è¿˜åŸ)
# ==========================================
st.sidebar.divider()
vocab_range = st.sidebar.slider("å­¦ä¹ åŒºé—´", 1, 20000, (6000, 8000), 500)
r_start, r_end = vocab_range

def process_text(text):
    text_lower = text.lower()
    words = re.findall(r'\b[a-z\']{2,}\b', text_lower)
    unique_words = sorted(list(set(words)))
    
    known, target, beyond = [], [], []
    
    for w in unique_words:
        rank = 99999
        match = w
        note = ""

        # A. ç›´æ¥æŸ¥ (is -> is?)
        if w in vocab_dict:
            rank = vocab_dict[w]
        
        # B. å¼ºåŠ›è¿˜åŸæŸ¥ (is -> be)
        if rank > 20000: # å¦‚æœç›´æ¥æŸ¥æ²¡æŸ¥åˆ°ï¼Œæˆ–è€…æŸ¥åˆ°äº†ä½†æ’åå¾ˆä½(å¯èƒ½æ˜¯é”™è¯¯æ¡ç›®)
            lemma = get_lemma_robust(w)
            if lemma in vocab_dict:
                # åªæœ‰å½“è¿˜åŸåçš„æ’åæ›´é å‰æ—¶ï¼Œæ‰é‡‡çº³
                lemma_rank = vocab_dict[lemma]
                if lemma_rank < rank:
                    rank = lemma_rank
                    match = lemma
                    note = f"<{w}>"

        item = {'å•è¯': match, 'æ’å': int(rank), 'å¤‡æ³¨': note}
        
        if rank <= r_start: known.append(item)
        elif r_start < rank <= r_end: target.append(item)
        else: beyond.append(item)

    return pd.DataFrame(known), pd.DataFrame(target), pd.DataFrame(beyond)

# ==========================================
# 4. ç•Œé¢
# ==========================================
text_input = st.text_area("åœ¨æ­¤ç²˜è´´æ–‡æœ¬:", height=150)

if st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary"):
    if not text_input: st.warning("è¯·è¾“å…¥å†…å®¹")
    else:
        df_k, df_t, df_b = process_text(text_input)
        
        st.success("åˆ†æå®Œæˆ")
        t1, t2, t3 = st.tabs([
            f"ğŸŸ¡ é‡ç‚¹ ({len(df_t)})", 
            f"ğŸ”´ ç”Ÿè¯/è¶…çº² ({len(df_b)})", 
            f"ğŸŸ¢ ç†Ÿè¯ ({len(df_k)})"
        ])
        
        with t1: st.dataframe(df_t, use_container_width=True)
        with t2: st.dataframe(df_b, use_container_width=True)
        with t3: st.dataframe(df_k, use_container_width=True)