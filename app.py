import streamlit as st
import pandas as pd
import re
import os
import simplemma

st.set_page_config(page_title="Vibe Vocab Studio", page_icon="ğŸ§ ", layout="wide")

# --- 1. æ™ºèƒ½åŠ è½½é…ç½® ---
POSSIBLE_FILES = ["coca_cleaned.csv", "data.csv", "COCA20000è¯Excelç‰ˆ.xlsx - Sheet1.csv"]
LANG_DATA = simplemma.load_data('en') # åŠ è½½è‹±è¯­è¿˜åŸåº“

@st.cache_data
def load_vocab():
    file_path = None
    for f in POSSIBLE_FILES:
        if os.path.exists(f):
            file_path = f
            break
            
    if not file_path:
        return None

    try:
        try:
            df = pd.read_csv(file_path)
        except:
            df = pd.read_csv(file_path, encoding='gbk')

        # æ¸…æ´—åˆ—å
        df.columns = [str(c).strip().lower().replace('\n', '') for c in df.columns]
        
        # æ™ºèƒ½æ‰¾åˆ—
        rank_col = next((c for c in df.columns if any(k in c for k in ['rank', 'æ’å', 'åºå·', 'è¯é¢‘'])), None)
        word_col = next((c for c in df.columns if any(k in c for k in ['word', 'å•è¯', 'è¯æ±‡'])), None)
        
        if not word_col: word_col = df.columns[0]
        if not rank_col: rank_col = df.columns[3] if len(df.columns) > 3 else df.columns[0]

        # å»ºç«‹å­—å…¸: word -> rank
        # å…³é”®ä¼˜åŒ–ï¼šæŠŠè¯åº“é‡Œçš„è¯ä¹Ÿéƒ½åšä¸€æ¬¡è¿˜åŸï¼Œç¡®ä¿å‘½ä¸­ç‡
        vocab_dict = pd.Series(
            pd.to_numeric(df[rank_col], errors='coerce').fillna(99999).values, 
            index=df[word_col].astype(str).str.lower().str.strip()
        ).to_dict()
        
        return vocab_dict
    except Exception as e:
        st.error(f"è¯åº“åŠ è½½å‡ºé”™: {e}")
        return None

# --- 2. æ ¸å¿ƒé€»è¾‘ (v4.0 å¼ºåŠ›è¿˜åŸç‰ˆ) ---
def process_text_smart(text, vocab_dict, range_start, range_end):
    text_lower = text.lower()
    # æå–å•è¯
    words = re.findall(r'\b[a-z\']{2,}\b', text_lower)
    unique_words = sorted(list(set(words)))
    
    tier_known = []   
    tier_target = []  
    tier_beyond = []  
    
    for w in unique_words:
        # === æ ¸å¿ƒä¿®æ”¹ï¼šä¸‰çº§è·³æŸ¥è¯æ³• ===
        rank = 999999
        match_word = w
        
        # 1. æŸ¥åŸè¯ (æ¯”å¦‚ "apple")
        if w in vocab_dict:
            rank = vocab_dict[w]
            match_word = w
        else:
            # 2. æŸ¥è¿˜åŸåçš„è¯ (æ¯”å¦‚ "went" -> "go", "countries" -> "country")
            lemma = simplemma.lemmatize(w, LANG_DATA)
            if lemma in vocab_dict:
                rank = vocab_dict[lemma]
                match_word = lemma # ä¿®æ­£æ˜¾ç¤ºä¸ºåŸå½¢ï¼Œæ–¹ä¾¿å­¦ä¹ 
            else:
                # 3. æœ€åçš„æŒ£æ‰ (å»æ‰ 's ç­‰)
                if w.endswith("'s") and w[:-2] in vocab_dict:
                    rank = vocab_dict[w[:-2]]
                    match_word = w[:-2]

        item = {'å•è¯ (Word)': match_word, 'åŸæ–‡ (Original)': w, 'æ’å (Rank)': int(rank)}
        
        # åˆ†çº§
        if rank <= range_start:
            tier_known.append(item)
        elif range_start < rank <= range_end:
            tier_target.append(item)
        else:
            # å¦‚æœåŸæ–‡å’Œè¿˜åŸåæ˜¯ä¸€æ ·çš„ï¼Œåªæ˜¾ç¤ºä¸€ä¸ªåˆ—
            if item['å•è¯ (Word)'] == item['åŸæ–‡ (Original)']:
                item['åŸæ–‡ (Original)'] = '-'
            tier_beyond.append(item)

    # ç»“æœç”Ÿæˆ
    def to_df(data):
        if not data: return pd.DataFrame()
        return pd.DataFrame(data).sort_values('æ’å (Rank)').drop_duplicates(subset=['å•è¯ (Word)'])

    return to_df(tier_known), to_df(tier_target), to_df(tier_beyond)

# --- 3. ç•Œé¢ UI ---
st.title("ğŸ§  Vibe Vocab v4.0 (æ™ºèƒ½è¿˜åŸç‰ˆ)")
st.caption("Simplemma é©±åŠ¨ Â· å®Œç¾å¤„ç†å˜ä½“/ä¸è§„åˆ™åŠ¨è¯")

vocab_dict = load_vocab()
if not vocab_dict:
    st.error("âŒ æ‰¾ä¸åˆ°è¯åº“æ–‡ä»¶ï¼")
    st.stop()

st.sidebar.header("âš™ï¸ å­¦ä¹ è§„åˆ’")
st.sidebar.success(f"ğŸ“š è¯åº“å·²å°±ç»ª")

st.sidebar.subheader("è®¾å®šèŒƒå›´")
vocab_range = st.sidebar.slider(
    "é€‰æ‹©åŒºé—´ï¼š", 1, 20000, (6000, 8000), 500
)
range_start, range_end = vocab_range

st.sidebar.info(
    f"ğŸŸ¢ **ç†Ÿè¯**: 1 - {range_start}\n\n"
    f"ğŸŸ¡ **é‡ç‚¹**: {range_start} - {range_end}\n\n"
    f"ğŸ”´ **è¶…çº²**: {range_end}+"
)

with st.expander("ğŸ“ æ–‡æœ¬è¾“å…¥", expanded=True):
    tab_paste, tab_upload = st.tabs(["ç²˜è´´æ–‡æœ¬", "ä¸Šä¼  TXT"])
    with tab_paste:
        text_input = st.text_area("åœ¨æ­¤ç²˜è´´:", height=150)
    with tab_upload:
        uploaded = st.file_uploader("ä¸Šä¼ æ–‡ä»¶", type="txt")
        if uploaded:
            text_input = uploaded.read().decode("utf-8")

final_text = text_input if text_input else ""

def show_download_buttons(df, prefix):
    if df.empty: return
    col1, col2 = st.columns(2)
    csv = df.to_csv(index=False).encode('utf-8')
    col1.download_button(f"ğŸ“¥ ä¸‹è½½ Excel", csv, f"{prefix}.csv", "text/csv")
    txt = "\n".join(df['å•è¯ (Word)'].tolist())
    col2.download_button(f"ğŸ“„ ä¸‹è½½ TXT", txt, f"{prefix}.txt", "text/plain")

if st.button("ğŸš€ å¼€å§‹æ™ºèƒ½åˆ†æ", type="primary"):
    if not final_text.strip():
        st.warning("è¯·å…ˆè¾“å…¥æ–‡æœ¬ï¼")
    else:
        df_known, df_target, df_beyond = process_text_smart(final_text, vocab_dict, range_start, range_end)
        
        st.success(f"åˆ†æå®Œæˆï¼")
        
        t1, t2, t3 = st.tabs([
            f"ğŸŸ¡ é‡ç‚¹çªç ´ ({len(df_target)})", 
            f"ğŸ”´ è¶…çº²/ç”Ÿè¯ ({len(df_beyond)})", 
            f"ğŸŸ¢ å·²æŒæ¡ ({len(df_known)})"
        ])
        
        with t1:
            st.markdown(f"### ğŸ¯ ä½ çš„æ ¸å¿ƒå­¦ä¹ åŒº ({range_start}-{range_end})")
            if not df_target.empty:
                st.dataframe(df_target, use_container_width=True)
                show_download_buttons(df_target, "target_words")
            else:
                st.info("æ²¡æœ‰å‘ç°æ­¤åŒºé—´çš„å•è¯ã€‚")

        with t2:
            st.markdown(f"### ğŸš€ è¶…çº²è¯ (>{range_end})")
            # è¶…çº²è¯å¾€å¾€æ˜¯è¿˜åŸå¤±è´¥çš„ï¼Œæˆ–è€…çœŸçš„å¾ˆå
            if not df_beyond.empty:
                st.dataframe(df_beyond, use_container_width=True)
                show_download_buttons(df_beyond, "beyond_words")
            else:
                st.info("æ²¡æœ‰è¶…çº²è¯æ±‡ï¼")

        with t3:
            st.markdown(f"### âœ… å·²æŒæ¡ (<{range_start})")
            if not df_known.empty:
                st.dataframe(df_known, use_container_width=True)
                show_download_buttons(df_known, "known_words")
            else:
                st.info("æ²¡æœ‰å‘ç°ç†Ÿè¯ã€‚")