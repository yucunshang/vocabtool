import streamlit as st
import pandas as pd
import re
import os

st.set_page_config(page_title="Vibe Vocab Studio", page_icon="âš¡", layout="wide")

# --- æ ¸å¿ƒé…ç½® ---
# è¿™é‡Œå†™æ­»æ–‡ä»¶åï¼Œå› ä¸ºä½ å·²ç»æŠŠå®ƒä¼ åˆ° GitHub äº†
DEFAULT_VOCAB_FILE = "coca_cleaned.csv" 

# --- æ ¸å¿ƒé€»è¾‘ ---
def get_sentence_context(text, word):
    """æå–åŸå¥"""
    sentences = re.split(r'(?<=[.!?])\s+', text)
    for sent in sentences:
        if re.search(r'\b' + re.escape(word) + r'\b', sent, re.IGNORECASE):
            return sent.strip()[:300]
    return "æœªæ‰¾åˆ°åŸå¥"

@st.cache_data
def load_vocab():
    """è‡ªåŠ¨åŠ è½½å†…ç½®è¯åº“"""
    if not os.path.exists(DEFAULT_VOCAB_FILE):
        return None
    try:
        # è¯»å– CSVï¼Œæ ‡å‡†åŒ–åˆ—å
        df = pd.read_csv(DEFAULT_VOCAB_FILE)
        df.columns = [c.strip().lower() for c in df.columns]
        return df
    except Exception as e:
        st.error(f"å†…ç½®è¯åº“è¯»å–å¤±è´¥: {e}")
        return None

def process_text_lite(text, vocab_df, user_limit):
    text_lower = text.lower()
    words = re.findall(r'\b[a-z]{2,}\b', text_lower)
    unique_words = sorted(list(set(words)))
    
    # å»ºç«‹å­—å…¸åŠ é€Ÿ
    if 'word' in vocab_df.columns and 'rank' in vocab_df.columns:
        vocab_dict = pd.Series(vocab_df['rank'].values, index=vocab_df['word'].astype(str)).to_dict()
    else:
        return pd.DataFrame(), pd.DataFrame()

    found_items = []
    for w in unique_words:
        rank = 999999
        match_word = w
        
        # åŒ¹é…é€»è¾‘
        if w in vocab_dict:
            rank = vocab_dict[w]
        elif w.endswith('s') and w[:-1] in vocab_dict:
            match_word = w[:-1]
            rank = vocab_dict[match_word]
        elif w.endswith('ed') and w[:-2] in vocab_dict:
            match_word = w[:-2]
            rank = vocab_dict[match_word]
        elif w.endswith('ing') and w[:-3] in vocab_dict:
            match_word = w[:-3]
            rank = vocab_dict[match_word]
            
        is_unknown = rank > user_limit
        context = get_sentence_context(text, w) if is_unknown else ""
            
        found_items.append({
            'word': match_word,
            'rank': rank,
            'is_known': not is_unknown,
            'context': context
        })

    df = pd.DataFrame(found_items)
    if not df.empty:
        return df[~df['is_known']].sort_values('rank'), df[df['is_known']].sort_values('rank')
    return pd.DataFrame(), pd.DataFrame()

# --- ç•Œé¢ UI ---
st.title("âš¡ Vibe Vocab Studio")
st.caption("å†…ç½® COCA 20000 è¯è¡¨ Â· è‡ªåŠ¨åˆ†çº§ Â· Anki åˆ¶å¡")

# åŠ è½½æ•°æ®
vocab_df = load_vocab()

if vocab_df is None:
    st.error(f"âŒ é”™è¯¯ï¼šåœ¨ä»“åº“ä¸­æ‰¾ä¸åˆ° {DEFAULT_VOCAB_FILE} æ–‡ä»¶ï¼è¯·ç¡®è®¤ä½ å·²ç»ä¸Šä¼ äº†è¯¥æ–‡ä»¶ã€‚")
    st.stop()

# ä¾§è¾¹æ  (ç®€åŒ–äº†ï¼Œä¸éœ€è¦ä¸Šä¼ æ–‡ä»¶)
st.sidebar.header("âš™ï¸ è®¾ç½®")
st.sidebar.success("âœ… å†…ç½®è¯åº“å·²åŠ è½½")
user_vocab = st.sidebar.slider("ä½ çš„è¯æ±‡é‡é˜ˆå€¼", 1000, 20000, 6000, 500)

# è¾“å…¥åŒº
with st.expander("ğŸ“ æ–‡æœ¬è¾“å…¥ (æ”¯æŒé•¿æ–‡æœ¬)", expanded=True):
    tab1, tab2 = st.tabs(["ç²˜è´´æ–‡æœ¬", "ä¸Šä¼ æ–‡ä»¶"])
    with tab1:
        text_input_raw = st.text_area("åœ¨æ­¤ç²˜è´´:", height=150)
    with tab2:
        uploaded_txt = st.file_uploader("ä¸Šä¼  .txt å°è¯´/æ–‡ç« ", type="txt")
        if uploaded_txt:
            text_input_raw = uploaded_txt.read().decode("utf-8")

final_text = text_input_raw if text_input_raw else ""

if st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary"):
    if not final_text.strip():
        st.warning("è¯·è¾“å…¥æ–‡æœ¬å†…å®¹ï¼")
    else:
        with st.spinner("æ­£åœ¨åˆ†æ..."):
            unknown_df, known_df = process_text_lite(final_text, vocab_df, user_vocab)
        
        st.success(f"åˆ†æå®Œæˆï¼å‘ç° {len(unknown_df)} ä¸ªç”Ÿè¯ã€‚")
        
        tab_unk, tab_kn, tab_anki = st.tabs(["ğŸ”´ ç”Ÿè¯è¡¨", "ğŸŸ¢ ç†Ÿè¯è¡¨", "ğŸ´ Anki åˆ¶å¡"])
        
        with tab_unk:
            st.dataframe(unknown_df[['word', 'rank', 'context']], use_container_width=True)
            csv = unknown_df.to_csv(index=False).encode('utf-8')
            st.download_button("ğŸ“¥ ä¸‹è½½ç”Ÿè¯ CSV", csv, "unknown.csv", "text/csv")

        with tab_kn:
            st.dataframe(known_df[['word', 'rank']], use_container_width=True)

        with tab_anki:
            st.info("å·²è‡ªåŠ¨ç”Ÿæˆ Anki å¯¼å…¥æ ¼å¼ (æ­£é¢:å•è¯ | èƒŒé¢:åŸå¥+æ’å)")
            if not unknown_df.empty:
                anki_df = pd.DataFrame()
                anki_df['Front'] = unknown_df['word']
                anki_df['Back'] = unknown_df['context'] + "<br><br>Rank: #" + unknown_df['rank'].astype(str)
                
                anki_csv = anki_df.to_csv(index=False, header=False).encode('utf-8')
                st.download_button("âš¡ ä¸‹è½½ Anki ç‰Œç»„", anki_csv, "anki_deck.csv", "text/csv")