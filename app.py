"""
Vocab Flow Ultra â€“ Streamlit entry point.
UI and session-state wiring; logic lives in constants, errors, utils,
resources, extraction, vocab, ai, anki_parse, tts, anki_package, state.
"""
import html
import logging
import os
import re
import time

import pandas as pd
import streamlit as st

import constants
import resources
from ai import CardFormat, build_card_prompt, get_word_quick_definition, process_ai_in_batches
from anki_package import cleanup_old_apkg_files, generate_anki_package
from anki_parse import parse_anki_data
from config import get_config
from extraction import (
    extract_text_from_file,
    extract_text_from_url,
    is_upload_too_large,
    parse_anki_txt_export,
)
from state import clear_all_state, set_generated_words_state
from utils import get_beijing_time_str, render_copy_button, run_gc
from vocab import analyze_logic

# Load vocab and expose to app (and to resources for vocab/ai modules)
VOCAB_DICT, FULL_DF = resources.load_vocab_data()
resources.VOCAB_DICT = VOCAB_DICT
resources.FULL_DF = FULL_DF

# Clean old .apkg files from our temp subdir (e.g. from previous sessions)
cleanup_old_apkg_files()

# Stop words to filter out in direct-input mode (articles, pronouns,
# prepositions, conjunctions, auxiliary verbs, determiners, etc.).
_DIRECT_INPUT_STOPWORDS: set = {
    # Articles & determiners
    "a", "an", "the", "this", "that", "these", "those",
    # Pronouns
    "i", "me", "my", "mine", "myself",
    "you", "your", "yours", "yourself", "yourselves",
    "he", "him", "his", "himself",
    "she", "her", "hers", "herself",
    "it", "its", "itself",
    "we", "us", "our", "ours", "ourselves",
    "they", "them", "their", "theirs", "themselves",
    "who", "whom", "whose", "which", "what",
    # Prepositions
    "in", "on", "at", "to", "for", "of", "with", "by", "from",
    "up", "out", "off", "into", "onto", "upon", "about", "over",
    "under", "after", "before", "between", "through", "during",
    "above", "below", "around", "against", "along", "across",
    "behind", "beyond", "within", "without", "toward", "towards",
    # Conjunctions
    "and", "but", "or", "nor", "so", "yet", "for",
    "both", "either", "neither", "whether",
    # Auxiliary / common verbs
    "is", "am", "are", "was", "were", "be", "been", "being",
    "do", "did", "does", "done", "doing",
    "has", "had", "have", "having",
    "will", "would", "shall", "should",
    "can", "could", "may", "might", "must",
    # Very common adverbs / particles
    "not", "no", "yes", "very", "too", "also", "just",
    "then", "than", "now", "here", "there",
    "how", "when", "where", "why",
    # Other function words
    "if", "as", "all", "each", "every", "any", "some",
    "such", "more", "most", "much", "many", "few",
    "other", "own", "same", "only",
}

logger = logging.getLogger(__name__)

# ==========================================
# Page Configuration
# ==========================================
st.set_page_config(
    page_title="Vocab Flow Ultra",
    page_icon="âš¡ï¸",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# Initialize Session State
for key, default_value in constants.DEFAULT_SESSION_STATE.items():
    if key not in st.session_state:
        st.session_state[key] = default_value

# Handle clickable word lookup via query params
_qp = st.query_params
_clicked_word = _qp.get("lookup_word", "")
if _clicked_word:
    st.query_params.clear()
    st.session_state["quick_lookup_word"] = _clicked_word
    st.session_state["_auto_lookup_word"] = _clicked_word

# Custom CSS â€“ app-like design
st.markdown("""
<style>
    /* ===== Global: hide Streamlit chrome, set base font ===== */
    #MainMenu, footer, header {visibility: hidden;}
    .stApp {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial,
                     'Noto Sans CJK SC', 'Microsoft YaHei', sans-serif;
    }

    /* ===== Smooth transitions on all interactive elements ===== */
    button, input, textarea, [data-baseweb="tab"], .stExpander {
        transition: all 0.2s ease !important;
    }

    /* ===== Buttons: pill-shaped, elevated feel ===== */
    .stButton>button {
        border-radius: 10px; font-weight: 600; width: 100%; margin-top: 4px;
        box-shadow: 0 1px 3px rgba(0,0,0,0.08);
        letter-spacing: 0.01em;
    }
    .stButton>button:hover {
        transform: translateY(-1px);
        box-shadow: 0 4px 12px rgba(0,0,0,0.10);
    }
    .stButton>button:active { transform: translateY(0); }

    /* ===== Text areas ===== */
    .stTextArea textarea {
        font-family: 'Consolas', 'SF Mono', 'Monaco', monospace;
        font-size: 14px; border-radius: 10px;
    }

    /* ===== Form cards ===== */
    .stForm {
        border: 1px solid #e5e7eb; border-radius: 14px;
        padding: 1.25rem 1.5rem; background: #fafbfc;
        box-shadow: 0 1px 4px rgba(0,0,0,0.04);
        margin-bottom: 1rem;
    }

    /* ===== Metric cards ===== */
    [data-testid="stMetric"] {
        background: linear-gradient(135deg, #f8fafc 0%, #f1f5f9 100%);
        padding: 1rem; border-radius: 12px;
        border: 1px solid #e2e8f0;
        box-shadow: 0 1px 3px rgba(0,0,0,0.04);
    }
    [data-testid="stMetric"] [data-testid="stMetricValue"] {
        font-weight: 700; letter-spacing: -0.02em;
    }

    /* ===== Tabs: segmented-control style ===== */
    .stTabs [data-baseweb="tab-list"] {
        gap: 4px; background: #f1f5f9; padding: 4px;
        border-radius: 12px; border: 1px solid #e2e8f0;
    }
    .stTabs [data-baseweb="tab"] {
        padding: 0.55rem 1rem; border-radius: 10px;
        font-weight: 500; font-size: 0.9rem;
    }
    .stTabs [data-baseweb="tab"][aria-selected="true"] {
        background: #fff; box-shadow: 0 1px 3px rgba(0,0,0,0.08);
    }

    /* ===== Expanders ===== */
    .stExpander {
        border: 1px solid #e5e7eb; border-radius: 12px;
        margin-bottom: 10px; overflow: hidden;
        box-shadow: 0 1px 2px rgba(0,0,0,0.03);
    }

    /* ===== Progress bar ===== */
    .stProgress > div > div > div > div {
        background: linear-gradient(90deg, #3b82f6 0%, #6366f1 100%);
        border-radius: 6px;
    }

    /* ===== Section dividers ===== */
    hr { border: none; height: 1px; background: #e5e7eb; margin: 1.5rem 0; }

    /* ===== App footer ===== */
    .app-footer {
        margin-top: 3rem; padding: 1.25rem 0; text-align: center;
        color: #94a3b8; font-size: 0.8rem; letter-spacing: 0.02em;
        border-top: 1px solid #f1f5f9;
    }

    /* ===== Hero header ===== */
    .app-hero {
        text-align: center; padding: 1.5rem 0 0.5rem;
    }
    .app-hero h1 {
        font-size: 1.75rem; font-weight: 800; letter-spacing: -0.03em;
        background: linear-gradient(135deg, #6366f1 0%, #3b82f6 50%, #06b6d4 100%);
        -webkit-background-clip: text; -webkit-text-fill-color: transparent;
        background-clip: text; margin-bottom: 0.25rem;
    }
    .app-hero p {
        color: #64748b; font-size: 0.9rem; margin: 0;
    }

    /* ===== Radio buttons: chip style ===== */
    .stRadio > div { gap: 0.4rem; }
    .stRadio > div > label {
        border: 1px solid #e2e8f0; border-radius: 8px;
        padding: 0.3rem 0.75rem; font-size: 0.85rem;
        transition: all 0.15s ease;
    }
    .stRadio > div > label:hover {
        border-color: #93c5fd; background: #f0f9ff;
    }

    /* ===== Number inputs ===== */
    .stNumberInput input { border-radius: 10px; }

    /* ===== Toast / info / warning boxes ===== */
    .stAlert { border-radius: 10px; }

    /* ===== Download button ===== */
    .stDownloadButton > button {
        border-radius: 10px; font-weight: 600;
        box-shadow: 0 2px 8px rgba(59,130,246,0.15);
    }
</style>
""", unsafe_allow_html=True)


def set_anki_pkg(file_path: str, deck_name: str) -> None:
    """Store Anki package path in session state and clean previous file."""
    if not file_path or not os.path.exists(file_path):
        raise FileNotFoundError("Generated Anki package file not found.")

    prev_path = st.session_state.get('anki_pkg_path')
    if prev_path and prev_path != file_path:
        try:
            if os.path.exists(prev_path):
                os.remove(prev_path)
        except OSError as e:
            logger.warning("Could not remove previous anki package: %s", e)

    st.session_state['anki_pkg_path'] = file_path
    st.session_state['anki_pkg_name'] = f"{deck_name}.apkg"


def render_anki_download_button(
    label: str,
    *,
    button_type: str = "primary",
    use_container_width: bool = False
) -> None:
    """Safely render Anki package download button if file exists."""
    file_path = st.session_state.get('anki_pkg_path')
    file_name = st.session_state.get('anki_pkg_name', "deck.apkg")

    if not file_path:
        return
    if not os.path.exists(file_path):
        st.warning("âš ï¸ ä¸‹è½½æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°ç”Ÿæˆã€‚")
        st.session_state['anki_pkg_path'] = ""
        return

    try:
        with open(file_path, "rb") as f:
            st.download_button(
                label=label,
                data=f.read(),
                file_name=file_name,
                mime="application/octet-stream",
                type=button_type,
                use_container_width=use_container_width
            )
    except OSError as e:
        logger.error("Failed to open package for download: %s", e)
        st.error("âŒ ä¸‹è½½æ–‡ä»¶è¯»å–å¤±è´¥ï¼Œè¯·é‡æ–°ç”Ÿæˆã€‚")


# ==========================================
# UI Components
# ==========================================


def render_card_format_selector(key_prefix: str) -> CardFormat:
    """Render card format options and return the selected CardFormat dict.

    ``key_prefix`` makes widget keys unique when called in multiple places.
    """
    st.markdown("#### âš™ï¸ å¡ç‰‡æ ¼å¼è‡ªå®šä¹‰")

    col_front, col_def = st.columns(2)
    with col_front:
        front_label = st.radio(
            "æ­£é¢å†…å®¹",
            options=list(constants.FRONT_OPTIONS.keys()),
            index=1,
            horizontal=True,
            key=f"{key_prefix}_front",
        )
    with col_def:
        def_label = st.radio(
            "é‡Šä¹‰è¯­è¨€",
            options=list(constants.DEFINITION_OPTIONS.keys()),
            index=0,
            horizontal=True,
            key=f"{key_prefix}_def",
        )

    col_ex, col_ety = st.columns(2)
    with col_ex:
        ex_label = st.radio(
            "ä¾‹å¥æ•°é‡",
            options=list(constants.EXAMPLE_COUNT_OPTIONS.keys()),
            index=0,
            horizontal=True,
            key=f"{key_prefix}_ex",
        )
    with col_ety:
        ety_label = st.radio(
            "è¯æºè¯æ ¹",
            options=list(constants.ETYMOLOGY_OPTIONS.keys()),
            index=0,
            horizontal=True,
            key=f"{key_prefix}_ety",
        )

    return CardFormat(
        front=constants.FRONT_OPTIONS[front_label],
        definition=constants.DEFINITION_OPTIONS[def_label],
        examples=constants.EXAMPLE_COUNT_OPTIONS[ex_label],
        etymology=constants.ETYMOLOGY_OPTIONS[ety_label],
    )


st.markdown("""
<div class="app-hero">
    <h1>Vocab Flow Ultra</h1>
    <p>æ–‡æœ¬ â†’ è¯è¡¨ â†’ Anki ç‰Œç»„ï¼Œä¸€æ­¥åˆ°ä½ Â· AI é‡Šä¹‰ Â· è¯æºæ‹†è§£ Â· å¹¶å‘è¯­éŸ³</p>
</div>
""", unsafe_allow_html=True)


def _do_lookup(query_word: str) -> None:
    """Execute AI lookup for a word, populating session state cache and result."""
    st.session_state["quick_lookup_is_loading"] = True
    try:
        cache_key = f"lookup_cache_{query_word.lower()}"
        if cache_key not in st.session_state:
            with st.spinner("ğŸ” æŸ¥è¯¢ä¸­..."):
                st.session_state[cache_key] = get_word_quick_definition(query_word)
            keys = st.session_state["quick_lookup_cache_keys"]
            keys.append(cache_key)
            while len(keys) > constants.QUICK_LOOKUP_CACHE_MAX:
                old_key = keys.pop(0)
                if old_key in st.session_state:
                    del st.session_state[old_key]
            st.session_state["quick_lookup_cache_keys"] = keys
        st.session_state["quick_lookup_last_query"] = query_word
        st.session_state["quick_lookup_last_result"] = st.session_state.get(cache_key)
    finally:
        st.session_state["quick_lookup_is_loading"] = False
        st.session_state["quick_lookup_block_until"] = time.time() + constants.QUICK_LOOKUP_COOLDOWN_SECONDS


def render_quick_lookup() -> None:
    st.markdown("### AI æé€ŸæŸ¥è¯")
    st.caption("è¾“å…¥å•è¯åæŒ‰å›è½¦æˆ–ç‚¹å‡»æŸ¥è¯¢ Â· é‡Šä¹‰ä¸­è‹±æ–‡å•è¯å¯ç‚¹å‡»ç»§ç»­æŸ¥è¯¢")

    if "quick_lookup_last_query" not in st.session_state:
        st.session_state["quick_lookup_last_query"] = ""
    if "quick_lookup_last_result" not in st.session_state:
        st.session_state["quick_lookup_last_result"] = None
    if "quick_lookup_is_loading" not in st.session_state:
        st.session_state["quick_lookup_is_loading"] = False
    if "quick_lookup_block_until" not in st.session_state:
        st.session_state["quick_lookup_block_until"] = 0.0
    if "quick_lookup_cache_keys" not in st.session_state:
        st.session_state["quick_lookup_cache_keys"] = []

    now_ts = time.time()
    in_cooldown = now_ts < st.session_state["quick_lookup_block_until"]
    lookup_disabled = st.session_state["quick_lookup_is_loading"] or in_cooldown

    # Apply pending lookup word before text_input widget is created.
    # This avoids mutating an already-instantiated widget state key.
    pending_word = st.session_state.pop("_quick_lookup_pending_word", "")
    if pending_word:
        st.session_state["quick_lookup_word"] = pending_word
        st.session_state["_auto_lookup_word"] = pending_word

    # Auto-lookup from clicked word (query param, pills, or word-block)
    auto_word = st.session_state.pop("_auto_lookup_word", "")
    if auto_word and not in_cooldown:
        _do_lookup(auto_word)

    with st.form("quick_lookup_form", clear_on_submit=False):
        col_word, col_btn = st.columns([4, 1])
        with col_word:
            lookup_word = st.text_input(
                "è¾“å…¥å•è¯æˆ–çŸ­è¯­",
                placeholder="å¦‚ï¼šserendipity, take off, run into...",
                key="quick_lookup_word",
                label_visibility="collapsed",
                autocomplete="off",
            )
        with col_btn:
            lookup_submit = st.form_submit_button(
                "æŸ¥è¯¢ä¸­..." if st.session_state["quick_lookup_is_loading"] else "æŸ¥è¯¢",
                type="primary",
                use_container_width=True,
                disabled=lookup_disabled
            )

    if in_cooldown:
        wait_seconds = max(0.0, st.session_state["quick_lookup_block_until"] - now_ts)
        st.caption(f"â±ï¸ è¯·ç¨å€™ {wait_seconds:.1f}s å†æ¬¡æŸ¥è¯¢")

    if lookup_submit:
        query_word = lookup_word.strip()
        if not query_word:
            st.warning("âš ï¸ è¯·è¾“å…¥å•è¯æˆ–çŸ­è¯­ã€‚")
        else:
            if st.session_state["quick_lookup_is_loading"]:
                st.info("â³ æŸ¥è¯¢è¿›è¡Œä¸­ï¼Œè¯·ç¨å€™ã€‚")
            elif time.time() < st.session_state["quick_lookup_block_until"]:
                st.info("â±ï¸ è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•ã€‚")
            else:
                _do_lookup(query_word)

    result = st.session_state.get("quick_lookup_last_result")
    if result and 'error' not in result:
        raw_content = result['result']
        rank = result.get('rank', 99999)

        if rank <= 5000:
            rank_color = "#10b981"
            rank_label = "é«˜é¢‘è¯"
        elif rank <= 10000:
            rank_color = "#3b82f6"
            rank_label = "å¸¸ç”¨è¯"
        elif rank <= 20000:
            rank_color = "#f59e0b"
            rank_label = "è¿›é˜¶è¯"
        elif rank < 99999:
            rank_color = "#ef4444"
            rank_label = "ä¸“ä¸šè¯"
        else:
            rank_color = "#6b7280"
            rank_label = "æœªæ”¶å½•"

        # Build styled HTML lines (no iframe needed)
        lines = raw_content.split('\n')
        formatted_lines = []
        clickable_words: list[str] = []

        current_query = st.session_state.get("quick_lookup_last_query", "").lower().strip()

        for line in lines:
            line = line.strip()
            if not line:
                continue

            # Collect English words from all result lines so users can
            # continue lookup from definitions, etymology, and examples.
            for w in re.findall(r"[a-zA-Z]{3,}", line):
                wl = w.lower()
                if wl == current_query:
                    continue
                if wl not in _DIRECT_INPUT_STOPWORDS and wl not in clickable_words:
                    clickable_words.append(wl)

            if line.startswith("ğŸŒ±"):
                safe = html.escape(line)
                formatted_lines.append(f'<div style="color:#065f46;background:#ecfdf5;padding:6px 10px;border-radius:8px;margin:8px 0;line-height:1.7;">{safe}</div>')
            elif "|" in line and len(line) < 50:
                safe = html.escape(line)
                formatted_lines.append(f'<div style="color:#1e3a8a;margin-bottom:6px;font-size:16px;line-height:1.7;">{safe}</div>')
            elif line.startswith("â€¢"):
                safe = html.escape(line)
                formatted_lines.append(f'<div style="color:#374151;margin-top:6px;font-size:16px;line-height:1.7;">{safe}</div>')
            else:
                safe = html.escape(line)
                formatted_lines.append(f'<div style="color:#6b7280;margin-bottom:8px;font-size:16px;line-height:1.7;">{safe}</div>')

        display_html = "".join(formatted_lines)
        rank_badge = f'<span style="display:inline-block;background:{rank_color};color:white;padding:3px 10px;border-radius:5px;font-size:13px;font-weight:600;">ğŸ“Š {rank} Â· {rank_label}</span>'

        st.markdown(f"""<div style="padding:4px 0;">{display_html}<div style="margin-top:10px;">{rank_badge}</div></div>""", unsafe_allow_html=True)

        # Clickable word pills for continuing lookup (pure Streamlit, no iframe)
        if clickable_words:
            picked = st.pills(
                "ç‚¹å‡»å•è¯ç»§ç»­æŸ¥è¯¢",
                options=clickable_words[:20],
                key="ql_word_pills",
                label_visibility="collapsed",
            )
            if "ql_word_pills_last" not in st.session_state:
                st.session_state["ql_word_pills_last"] = ""
            if picked and picked != st.session_state["ql_word_pills_last"]:
                st.session_state["ql_word_pills_last"] = picked
                st.session_state["_quick_lookup_pending_word"] = picked
                st.rerun()

    elif result and 'error' in result:
        st.error(f"âŒ æŸ¥è¯¢å¤±è´¥ï¼š{result.get('error', 'æœªçŸ¥é”™è¯¯')}")

    st.markdown("---")


if hasattr(st, "fragment"):
    render_quick_lookup = st.fragment(render_quick_lookup)

render_quick_lookup()

if not VOCAB_DICT:
    st.error("âš ï¸ ç¼ºå¤± `coca_cleaned.csv` æˆ– `vocab.pkl` æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ç›®å½•ã€‚")

with st.expander("ä½¿ç”¨æŒ‡å— & æ”¯æŒæ ¼å¼", expanded=False):
    st.markdown("""
    **æé€Ÿå·¥ä½œæµ**
    1. **æŸ¥è¯** â€” é¡¶éƒ¨ AI æŸ¥è¯ï¼Œç§’é€Ÿè·å–ç²¾å‡†é‡Šä¹‰ã€è¯æºæ‹†è§£å’ŒåŒè¯­ä¾‹å¥
    2. **æå–** â€” æ”¯æŒ PDF / ePub / Docx / TXT / CSV / Excel ç­‰æ ¼å¼
    3. **ç”Ÿæˆ** â€” AI é‡Šä¹‰ + å¹¶å‘è¯­éŸ³åˆæˆï¼Œä¸€é”®æ‰“åŒ…ä¸‹è½½

    **æ”¯æŒçš„æ–‡ä»¶æ ¼å¼**
    TXT Â· PDF Â· DOCX Â· EPUB Â· CSV Â· XLSX Â· XLS Â· DB Â· SQLite Â· Anki å¯¼å‡º (.txt)
    """)

tab_extract, tab_anki = st.tabs([
    "å•è¯æå–",
    "å¡ç‰‡åˆ¶ä½œ"
])

# ==========================================
# Tab 1: Word Extraction
# ==========================================
with tab_extract:
    mode_context, mode_direct, mode_rank = st.tabs([
        "è¯­å¢ƒåˆ†æ",
        "ç›´æ¥è¾“å…¥",
        "è¯é¢‘åˆ—è¡¨"
    ])

    with mode_context:
        col1, col2 = st.columns(2)
        current_rank = col1.number_input("å¿½ç•¥å‰ N é«˜é¢‘è¯ (Min Rank)", 1, 20000, 6000, step=100)
        target_rank = col2.number_input("å¿½ç•¥å N ä½é¢‘è¯ (Max Rank)", 2000, 50000, 10000, step=500)

        if target_rank < current_rank:
            st.warning("âš ï¸ Max Rank å¿…é¡»å¤§äºç­‰äº Min Rank")

        st.markdown("#### ğŸ“¥ å¯¼å…¥å†…å®¹")

        input_url = st.text_input(
            "ğŸ”— è¾“å…¥æ–‡ç«  URL (è‡ªåŠ¨æŠ“å–)",
            placeholder="https://www.economist.com/...",
            key="url_input_key"
        )

        uploaded_file = st.file_uploader(
            "æˆ–ç›´æ¥ä¸Šä¼ æ–‡ä»¶",
            type=['txt', 'pdf', 'docx', 'epub', 'csv', 'xlsx', 'xls', 'db', 'sqlite'],
            key=st.session_state['uploader_id'],
            label_visibility="collapsed"
        )
        if uploaded_file and is_upload_too_large(uploaded_file):
            st.error(f"âŒ æ–‡ä»¶è¿‡å¤§ï¼Œå·²é™åˆ¶ä¸º {constants.MAX_UPLOAD_MB}MBã€‚è¯·ç¼©å°æ–‡ä»¶åé‡è¯•ã€‚")
            uploaded_file = None

        pasted_text = st.text_area(
            "æˆ–åœ¨æ­¤ç²˜è´´æ–‡æœ¬",
            height=100,
            key="paste_key",
            placeholder="æ”¯æŒç›´æ¥ç²˜è´´æ–‡ç« å†…å®¹..."
        )

        if st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary"):
            if target_rank < current_rank:
                st.error("âŒ Max Rank å¿…é¡»å¤§äºç­‰äº Min Rankï¼Œè¯·ä¿®æ­£åé‡è¯•ã€‚")
            else:
                with st.status("ğŸ” æ­£åœ¨åŠ è½½èµ„æºå¹¶åˆ†ææ–‡æœ¬...", expanded=True) as status:
                    start_time = time.time()
                    raw_text = ""

                    if input_url:
                        status.write(f"ğŸŒ æ­£åœ¨æŠ“å– URL: {input_url}...")
                        raw_text = extract_text_from_url(input_url)
                    elif uploaded_file:
                        raw_text = extract_text_from_file(uploaded_file)
                    else:
                        raw_text = pasted_text

                    if len(raw_text) > 2:
                        status.write("ğŸ§  æ­£åœ¨è¿›è¡Œ NLP è¯å½¢è¿˜åŸä¸åˆ†çº§...")
                        final_data, raw_count, stats_info = analyze_logic(
                            raw_text, current_rank, target_rank, False
                        )

                        set_generated_words_state(final_data, raw_count, stats_info)
                        st.session_state['process_time'] = time.time() - start_time
                        run_gc()
                        status.update(label="âœ… åˆ†æå®Œæˆ", state="complete", expanded=False)
                    else:
                        status.update(label="âš ï¸ å†…å®¹ä¸ºç©ºæˆ–å¤ªçŸ­", state="error")

    with mode_direct:
        st.markdown("#### ğŸ“¤ å¯¼å…¥ Anki ç‰Œç»„å¯¼å‡ºæ–‡ä»¶ (å¯é€‰)")
        st.caption("ğŸ’¡ æç¤ºï¼šåœ¨ Anki å¯¼å‡ºæ—¶ï¼Œæ¨èé€‰æ‹© **'Notes in Plain Text'** (ç¬”è®°çº¯æ–‡æœ¬)ã€‚ä½†å¦‚æœæ‚¨é€‰æ‹©äº† **'Cards in Plain Text'**ï¼Œç³»ç»Ÿä¹Ÿä¼šå°è¯•è‡ªåŠ¨è§£æã€‚")

        anki_export_file = st.file_uploader(
            "ä¸Šä¼  Anki å¯¼å‡ºçš„ .txt æ–‡ä»¶",
            type=['txt'],
            key="anki_import_uploader"
        )
        if anki_export_file and is_upload_too_large(anki_export_file):
            st.error(f"âŒ æ–‡ä»¶è¿‡å¤§ï¼Œå·²é™åˆ¶ä¸º {constants.MAX_UPLOAD_MB}MBã€‚è¯·ç¼©å°æ–‡ä»¶åé‡è¯•ã€‚")
            anki_export_file = None

        prefilled_text = ""
        if anki_export_file:
            with st.spinner("æ­£åœ¨æ™ºèƒ½è§£æ Anki å¯¼å‡ºæ–‡ä»¶..."):
                prefilled_text = parse_anki_txt_export(anki_export_file)
                if prefilled_text:
                    st.success(f"âœ… æˆåŠŸæå– {len(prefilled_text.splitlines())} ä¸ªå•è¯")

        raw_input = st.text_area(
            "âœï¸ ç²˜è´´å•è¯åˆ—è¡¨ (æ¯è¡Œä¸€ä¸ª æˆ– é€—å·åˆ†éš”)",
            height=200,
            value=prefilled_text,
            placeholder="altruism\nhectic\nserendipity"
        )

        if st.button("ğŸš€ ç”Ÿæˆåˆ—è¡¨", key="btn_direct", type="primary"):
            with st.spinner("æ­£åœ¨è§£æåˆ—è¡¨..."):
                if raw_input.strip():
                    words = [w.strip() for w in re.split(r'[,\n\t]+', raw_input) if w.strip()]
                    unique_words = []
                    seen = set()

                    for word in words:
                        w_lower = word.lower().strip()
                        if not w_lower or w_lower in seen:
                            continue
                        # Skip non-alphabetic tokens
                        if not re.match(r'^[a-zA-Z]+(?:[-\' ][a-zA-Z]+)*$', w_lower):
                            continue
                        # Skip single characters and very short stop words
                        if len(w_lower) <= 1:
                            continue
                        # Skip common stop words / function words
                        if w_lower in _DIRECT_INPUT_STOPWORDS:
                            continue
                        seen.add(w_lower)
                        unique_words.append(word)

                    raw_count = len(words)
                    data_list = [(w, VOCAB_DICT.get(w.lower(), 99999)) for w in unique_words]
                    set_generated_words_state(data_list, raw_count, None)
                    filtered = raw_count - len(unique_words)
                    msg = f"âœ… å·²åŠ è½½ {len(unique_words)} ä¸ªå•è¯"
                    if filtered > 0:
                        msg += f"ï¼ˆå·²è¿‡æ»¤ {filtered} ä¸ªæ— å…³è¯ï¼‰"
                    st.toast(msg, icon="ğŸ‰")
                else:
                    st.warning("âš ï¸ å†…å®¹ä¸ºç©ºã€‚")

    with mode_rank:
        gen_type = st.radio("ç”Ÿæˆæ¨¡å¼", ["ğŸ”¢ é¡ºåºç”Ÿæˆ", "ğŸ”€ éšæœºæŠ½å–"], horizontal=True)

        if "é¡ºåºç”Ÿæˆ" in gen_type:
            col_a, col_b = st.columns(2)
            start_rank = col_a.number_input("èµ·å§‹æ’å", 1, 20000, 8000, step=100)
            count = col_b.number_input("æ•°é‡", 10, 5000, 10, step=10)

            if st.button("ğŸš€ ç”Ÿæˆåˆ—è¡¨"):
                with st.spinner("æ­£åœ¨æå–..."):
                    if FULL_DF is not None:
                        rank_col = next(c for c in FULL_DF.columns if 'rank' in c)
                        word_col = next(c for c in FULL_DF.columns if 'word' in c)
                        subset = FULL_DF[FULL_DF[rank_col] >= start_rank].sort_values(rank_col).head(count)
                        set_generated_words_state(
                            list(zip(subset[word_col], subset[rank_col])),
                            0,
                            None
                        )
        else:
            col_min, col_max, col_cnt = st.columns([1, 1, 1])
            min_rank = col_min.number_input("æœ€å°æ’å", 1, 20000, 12000, step=100)
            max_rank = col_max.number_input("æœ€å¤§æ’å", 1, 25000, 15000, step=100)
            random_count = col_cnt.number_input("æŠ½å–æ•°é‡", 10, 5000, 10, step=10)

            if max_rank < min_rank:
                st.warning("âš ï¸ æœ€å¤§æ’åå¿…é¡»å¤§äºç­‰äºæœ€å°æ’å")

            if st.button("ğŸ² éšæœºæŠ½å–"):
                if max_rank < min_rank:
                    st.error("âŒ æœ€å¤§æ’åå¿…é¡»å¤§äºç­‰äºæœ€å°æ’åï¼Œè¯·ä¿®æ­£åé‡è¯•ã€‚")
                else:
                    with st.spinner("æ­£åœ¨æŠ½å–..."):
                        if FULL_DF is not None:
                            rank_col = next(c for c in FULL_DF.columns if 'rank' in c)
                            word_col = next(c for c in FULL_DF.columns if 'word' in c)
                            pool = FULL_DF[(FULL_DF[rank_col] >= min_rank) & (FULL_DF[rank_col] <= max_rank)]
                            if len(pool) < random_count:
                                st.warning(f"âš ï¸ è¯¥èŒƒå›´åªæœ‰ {len(pool)} ä¸ªå•è¯ï¼Œå·²å…¨éƒ¨é€‰ä¸­")
                            sample = pool.sample(n=min(random_count, len(pool)))
                            set_generated_words_state(
                                list(zip(sample[word_col], sample[rank_col])),
                                0,
                                None
                            )

    # Display results (shared across all modes)
    if st.session_state.get('gen_words_data'):
        data = st.session_state['gen_words_data']
        original_count = len(data)

        if st.session_state.get('stats_info'):
            stats = st.session_state['stats_info']
            col_s1, col_s2 = st.columns(2)
            with col_s1:
                st.metric("ğŸ“Š è¯æ±‡è¦†ç›–ç‡", f"{stats['coverage']*100:.1f}%")
            with col_s2:
                st.metric("ğŸ¯ ç›®æ ‡è¯å¯†åº¦", f"{stats['target_density']*100:.1f}%")

        raw_count = st.session_state.get('raw_count', 0)
        if not raw_count:
            raw_count = original_count
        col_t1, col_t2 = st.columns(2)
        with col_t1:
            st.metric("ğŸ“¦ æå–çš„å•è¯æ€»æ•°", raw_count)
        with col_t2:
            st.metric("âœ… ç­›é€‰åå•è¯æ€»æ•°", original_count)

        st.markdown(f"### âœ… æå–æˆåŠŸï¼")

        words_only = [w for w, r in data]
        words_text = "\n".join(words_only)
        if "word_list_editor" not in st.session_state:
            st.session_state["word_list_editor"] = words_text

        col_title, col_copy_btn = st.columns([5, 1])
        with col_title:
            st.markdown("### ğŸ“ å•è¯åˆ—è¡¨")
        with col_copy_btn:
            current_words_text = st.session_state.get("word_list_editor", words_text)
            render_copy_button(current_words_text, key="copy_words_btn")
        st.caption("ğŸ’¡ å¯ä»¥åœ¨ä¸‹æ–¹æ–‡æœ¬æ¡†ä¸­ç¼–è¾‘ã€æ–°å¢æˆ–åˆ é™¤å•è¯ï¼Œæ¯è¡Œä¸€ä¸ªå•è¯")

        edited_words = st.text_area(
            f"âœï¸ å•è¯åˆ—è¡¨ (å…± {original_count} ä¸ª)",
            height=300,
            key="word_list_editor",
            label_visibility="collapsed",
            help="æ¯è¡Œä¸€ä¸ªå•è¯"
        )

        if edited_words != words_text:
            edited_word_list = [w.strip() for w in edited_words.split('\n') if w.strip()]
            st.info(f"ğŸ“ å·²ç¼–è¾‘ï¼šå½“å‰å…± {len(edited_word_list)} ä¸ªå•è¯")
            words_only = edited_word_list
        else:
            words_only = [w for w, r in data]

        st.markdown("---")
        st.markdown("### ğŸ¤– AI ç”Ÿæˆ Anki å¡ç‰‡")

        col_ai_btn, col_copy_hint = st.columns([1, 1.35], vertical_alignment="top")

        with col_ai_btn:
            ai_model_label = get_config()["openai_model"]

            selected_voice_label = st.radio(
                "ğŸ™ï¸ å‘éŸ³äºº",
                options=list(constants.VOICE_MAP.keys()),
                index=0,
                horizontal=False,
                key="sel_voice_auto"
            )
            selected_voice_code = constants.VOICE_MAP[selected_voice_label]

            enable_audio_auto = st.checkbox("å¯ç”¨è¯­éŸ³", value=True, key="chk_audio_auto")

            # Keep full list for third-party prompt; only cap built-in AI path.
            words_for_auto_ai = words_only
            current_word_count = len(words_for_auto_ai)
            if current_word_count > constants.MAX_AUTO_LIMIT:
                st.caption(
                    f"âš ï¸ å½“å‰ {current_word_count} è¯ï¼›å†…ç½® AI æœ€å¤šå¤„ç†å‰ {constants.MAX_AUTO_LIMIT} è¯ã€‚"
                    " å¦‚éœ€å…¨éƒ¨å¤„ç†ï¼Œè¯·ä½¿ç”¨å³ä¾§ç¬¬ä¸‰æ–¹ Prompt åˆ†æ‰¹ã€‚"
                )
                words_for_auto_ai = words_for_auto_ai[:constants.MAX_AUTO_LIMIT]

            if st.button(f"ğŸš€ ä½¿ç”¨ {ai_model_label} ç”Ÿæˆ", type="primary", use_container_width=True):
                progress_title = st.empty()
                stage_text = st.empty()
                overall_bar = st.progress(0.0)
                ai_bar = st.progress(0.0)
                ai_text = st.empty()
                pkg_bar = st.progress(0.0)
                pkg_text = st.empty()

                def render_stages(ai_status: str, parse_status: str, pkg_status: str) -> None:
                    stage_text.markdown(
                        f"**æµç¨‹è¿›åº¦**  \n"
                        f"1) AI æ‰¹é‡ç”Ÿæˆï¼š{ai_status}  \n"
                        f"2) ç»“æœè§£æï¼š{parse_status}  \n"
                        f"3) æ‰“åŒ…/è¯­éŸ³ï¼š{pkg_status}"
                    )

                progress_title.markdown("#### â³ å†…ç½® AI åˆ¶å¡è¿›åº¦")
                render_stages("è¿›è¡Œä¸­", "ç­‰å¾…ä¸­", "ç­‰å¾…ä¸­")
                ai_text.text("AI ç”Ÿæˆï¼šå‡†å¤‡ä¸­...")
                pkg_text.text("æ‰“åŒ…/è¯­éŸ³ï¼šç­‰å¾…ä¸­...")

                def update_ai_progress(current: int, total: int) -> None:
                    ratio = current / total if total > 0 else 0.0
                    ai_bar.progress(ratio)
                    overall_bar.progress(min(0.70, ratio * 0.70))
                    ai_text.text(f"AI ç”Ÿæˆï¼šå·²å¤„ç† {current}/{total}")

                ai_result = process_ai_in_batches(
                    words_for_auto_ai,
                    progress_callback=update_ai_progress,
                )

                if ai_result:
                    ai_bar.progress(1.0)
                    overall_bar.progress(0.75)
                    render_stages("å®Œæˆ", "è¿›è¡Œä¸­", "ç­‰å¾…ä¸­")
                    ai_text.text("AI ç”Ÿæˆï¼šå®Œæˆ")
                    pkg_text.text("æ‰“åŒ…/è¯­éŸ³ï¼šç­‰å¾…ä¸­...")
                    parsed_data = parse_anki_data(ai_result)

                    if parsed_data:
                        try:
                            overall_bar.progress(0.80)
                            render_stages("å®Œæˆ", "å®Œæˆ", "è¿›è¡Œä¸­")
                            pkg_text.text("æ‰“åŒ…/è¯­éŸ³ï¼šæ­£åœ¨ç”Ÿæˆ Anki åŒ…...")
                            deck_name = f"Vocab_{get_beijing_time_str()}"

                            def update_pkg_progress(ratio: float, text: str) -> None:
                                pkg_bar.progress(ratio)
                                overall_bar.progress(min(1.0, 0.80 + ratio * 0.20))
                                pkg_text.text(f"æ‰“åŒ…/è¯­éŸ³ï¼š{text}")

                            file_path = generate_anki_package(
                                parsed_data,
                                deck_name,
                                enable_tts=enable_audio_auto,
                                tts_voice=selected_voice_code,
                                progress_callback=update_pkg_progress
                            )

                            set_anki_pkg(file_path, deck_name)

                            pkg_bar.progress(1.0)
                            overall_bar.progress(1.0)
                            render_stages("å®Œæˆ", "å®Œæˆ", "å®Œæˆ")
                            pkg_text.markdown(f"âœ… **å¤„ç†å®Œæˆï¼å…±ç”Ÿæˆ {len(parsed_data)} å¼ å¡ç‰‡**")
                            st.balloons()
                            run_gc()
                        except Exception as e:
                            render_stages("å®Œæˆ", "å®Œæˆ", "å¤±è´¥")
                            from errors import ErrorHandler
                            ErrorHandler.handle(e, "ç”Ÿæˆå‡ºé”™")
                    else:
                        render_stages("å®Œæˆ", "å¤±è´¥", "æœªå¼€å§‹")
                        st.error("è§£æå¤±è´¥ï¼ŒAI è¿”å›å†…å®¹ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯ã€‚")
                else:
                    render_stages("å¤±è´¥", "æœªå¼€å§‹", "æœªå¼€å§‹")
                    st.error("AI ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥ API Key æˆ–ç½‘ç»œè¿æ¥ã€‚")

            render_anki_download_button(
                f"ğŸ“¥ ä¸‹è½½ {st.session_state.get('anki_pkg_name', 'deck.apkg')}",
                button_type="primary",
                use_container_width=True
            )
            st.caption("âš ï¸ AI ç»“æœè¯·äººå·¥å¤æ ¸åå†å­¦ä¹ ã€‚")

        with col_copy_hint:
            st.markdown("#### ç¬¬ä¸‰æ–¹ AI Prompt")
            st.caption("å†…ç½® AI é€‚åˆå¿«é€Ÿç”Ÿæˆï¼›éœ€è¦æ›´å¤§æ‰¹é‡æ—¶ï¼Œä½¿ç”¨ä¸‹æ–¹ Prompt åˆ°ç¬¬ä¸‰æ–¹ AIã€‚")

            with st.expander("ğŸ“Œ å¤åˆ¶ Promptï¼ˆç¬¬ä¸‰æ–¹ AIï¼‰", expanded=False):
                card_fmt = render_card_format_selector("tab1_prompt")
                batch_size_prompt = int(
                    st.number_input("ğŸ”¢ åˆ†ç»„å¤§å° (æœ€å¤§ 500)", min_value=1, max_value=500, value=50, step=10)
                )
                current_batch_words = []

                if words_only:
                    total_w = len(words_only)
                    if total_w <= 500:
                        st.caption(f"ğŸ’¡ å½“å‰å…± {total_w} ä¸ªå•è¯ï¼ˆâ‰¤500ï¼‰ï¼Œå·²å…¨éƒ¨æ”¾å…¥ä¸€ä¸ª Promptã€‚")
                        current_batch_words = words_only
                    else:
                        num_batches = (total_w + batch_size_prompt - 1) // batch_size_prompt
                        batch_options = [
                            f"ç¬¬ {i+1} ç»„ ({i*batch_size_prompt+1} - {min((i+1)*batch_size_prompt, total_w)})"
                            for i in range(num_batches)
                        ]
                        selected_batch_str = st.selectbox("ğŸ“‚ é€‰æ‹©å½“å‰åˆ†ç»„", batch_options)
                        sel_idx = batch_options.index(selected_batch_str)
                        current_batch_words = words_only[
                            sel_idx*batch_size_prompt:min((sel_idx+1)*batch_size_prompt, total_w)
                        ]
                else:
                    st.warning("âš ï¸ æš‚æ— å•è¯æ•°æ®ï¼Œè¯·å…ˆæå–å•è¯ã€‚")

                words_str_for_prompt = ", ".join(current_batch_words) if current_batch_words else "[INSERT YOUR WORD LIST HERE]"
                strict_prompt_template = build_card_prompt(words_str_for_prompt, card_fmt)
                st.code(strict_prompt_template, language="text")

# ==========================================
# Tab 2: Manual Anki Card Creation
# ==========================================
with tab_anki:
    st.markdown("### ğŸ“¦ æ‰‹åŠ¨åˆ¶ä½œ Anki ç‰Œç»„")

    if 'anki_cards_cache' not in st.session_state:
        st.session_state['anki_cards_cache'] = None

    def reset_anki_state() -> None:
        st.session_state['anki_cards_cache'] = None
        if st.session_state.get('anki_pkg_path'):
            try:
                if os.path.exists(st.session_state['anki_pkg_path']):
                    os.remove(st.session_state['anki_pkg_path'])
            except OSError as e:
                logger.warning("Could not remove temp anki package: %s", e)
        st.session_state['anki_pkg_path'] = ""
        st.session_state['anki_pkg_name'] = ""
        st.session_state['anki_input_text'] = ""

    beijing_time_str = get_beijing_time_str()
    deck_name = st.text_input("ğŸ·ï¸ ç‰Œç»„åç§°", f"Vocab_{beijing_time_str}")

    ai_response = st.text_area(
        "ç²˜è´´ AI è¿”å›å†…å®¹",
        height=300,
        key="anki_input_text",
        placeholder='hectic ||| å¿™ä¹±çš„ ||| She has a hectic schedule today.',
    )

    manual_voice_label = st.radio(
        "ğŸ™ï¸ å‘éŸ³äºº",
        options=list(constants.VOICE_MAP.keys()),
        index=0,
        horizontal=True,
        key="sel_voice_manual",
    )
    manual_voice_code = constants.VOICE_MAP[manual_voice_label]

    enable_audio = st.checkbox("å¯ç”¨è¯­éŸ³", value=True, key="chk_audio_manual")

    col_btn1, col_btn2 = st.columns([1, 4])
    with col_btn1:
        start_gen = st.button("ğŸš€ ç”Ÿæˆå¡ç‰‡", type="primary", use_container_width=True)
    with col_btn2:
        st.button("ğŸ—‘ï¸ æ¸…ç©ºé‡ç½®", type="secondary", on_click=reset_anki_state, key="btn_clear_anki")

    if start_gen:
        if not ai_response.strip():
            st.warning("âš ï¸ è¾“å…¥æ¡†ä¸ºç©ºã€‚")
        else:
            progress_container = st.container()
            with progress_container:
                progress_bar_manual = st.progress(0)
                status_manual = st.empty()

            def update_progress_manual(ratio: float, text: str) -> None:
                progress_bar_manual.progress(ratio)
                status_manual.text(text)

            with st.spinner("â³ æ­£åœ¨è§£æå¹¶ç”Ÿæˆ..."):
                parsed_data = parse_anki_data(ai_response)
                if parsed_data:
                    st.session_state['anki_cards_cache'] = parsed_data
                    try:
                        file_path = generate_anki_package(
                            parsed_data,
                            deck_name,
                            enable_tts=enable_audio,
                            tts_voice=manual_voice_code,
                            progress_callback=update_progress_manual
                        )

                        set_anki_pkg(file_path, deck_name)

                        status_manual.markdown(f"âœ… **ç”Ÿæˆå®Œæ¯•ï¼å…±åˆ¶ä½œ {len(parsed_data)} å¼ å¡ç‰‡**")
                        st.balloons()
                        st.toast("ä»»åŠ¡å®Œæˆï¼", icon="ğŸ‰")
                        run_gc()
                    except Exception as e:
                        from errors import ErrorHandler
                        ErrorHandler.handle(e, "ç”Ÿæˆæ–‡ä»¶å‡ºé”™")
                else:
                    st.error("âŒ è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥è¾“å…¥æ ¼å¼ã€‚")

    if st.session_state['anki_cards_cache']:
        cards = st.session_state['anki_cards_cache']
        with st.expander(f"ğŸ‘€ é¢„è§ˆå¡ç‰‡ (å‰ {constants.MAX_PREVIEW_CARDS} å¼ )", expanded=False):
            df_view = pd.DataFrame(cards)
            display_cols = ['w', 'm', 'e', 'r']
            df_view = df_view[[c for c in display_cols if c in df_view.columns]]
            col_labels = ["æ­£é¢", "ä¸­æ–‡/è‹±æ–‡é‡Šä¹‰", "ä¾‹å¥"]
            if len(df_view.columns) > 3:
                col_labels.append("è¯æº")
            df_view.columns = col_labels[:len(df_view.columns)]
            st.dataframe(df_view.head(constants.MAX_PREVIEW_CARDS), use_container_width=True, hide_index=True)

        render_anki_download_button(
            f"ğŸ“¥ ä¸‹è½½ {st.session_state.get('anki_pkg_name', 'deck.apkg')}",
            button_type="primary"
        )

st.markdown(
    '<div class="app-footer">Vocab Flow Ultra &nbsp;Â·&nbsp; Built for learners</div>',
    unsafe_allow_html=True
)
