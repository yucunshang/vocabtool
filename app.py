import streamlit as st
import pandas as pd
import re
import os
from io import BytesIO

st.set_page_config(page_title="Vibe Vocab Studio", page_icon="ğŸ¯", layout="wide")

# --- 1. æ™ºèƒ½åŠ è½½é…ç½® ---
# ä¼˜å…ˆæ‰¾æ¸…æ´—è¿‡çš„æ–‡ä»¶ï¼Œæ‰¾ä¸åˆ°å°±æ‰¾åŸå§‹åï¼Œæ–¹ä¾¿ç”¨æˆ·å·æ‡’
POSSIBLE_FILES = ["coca_cleaned.csv", "data.csv", "COCA20000è¯Excelç‰ˆ.xlsx - Sheet1.csv"]

@st.cache_data
def load_vocab():
    """è¯»å–å¹¶æ™ºèƒ½è¯†åˆ«è¯åº“"""
    file_path = None
    for f in POSSIBLE_FILES:
        if os.path.exists(f):
            file_path = f
            break
            
    if not file_path:
        return None

    try:
        # è¯»å–æ–‡ä»¶
        try:
            df = pd.read_csv(file_path)
        except:
            df = pd.read_csv(file_path, encoding='gbk') # å°è¯•gbké˜²ä¹±ç 

        # === æ™ºèƒ½åˆ—åæ˜ å°„ (å…³é”®æ›´æ–°) ===
        # æŠŠæ‰€æœ‰åˆ—åè½¬å°å†™ã€å»ç©ºæ ¼
        df.columns = [str(c).strip().lower().replace('\n', '') for c in df.columns]
        
        # å¯»æ‰¾ Rank åˆ— (æ”¯æŒä¸­æ–‡)
        rank_col = None
        for c in df.columns:
            if any(k in c for k in ['rank', 'æ’å', 'åºå·', 'è¯é¢‘']):
                rank_col = c
                break
        
        # å¯»æ‰¾ Word åˆ— (æ”¯æŒä¸­æ–‡)
        word_col = None
        for c in df.columns:
            if any(k in c for k in ['word', 'å•è¯', 'è¯æ±‡']):
                word_col = c
                break
        
        # å…œåº•ï¼šå¦‚æœæ‰¾ä¸åˆ°ï¼Œç›²çŒœç¬¬1åˆ—å’Œç¬¬4åˆ—(æ ¹æ®ä½ çš„æ–‡ä»¶ç»“æ„)
        if not word_col: word_col = df.columns[0]
        if not rank_col: rank_col = df.columns[3] if len(df.columns) > 3 else df.columns[0]

        # å»ºç«‹å­—å…¸: word -> rank
        vocab_dict = pd.Series(
            pd.to_numeric(df[rank_col], errors='coerce').fillna(99999).values, 
            index=df[word_col].astype(str).str.lower().str.strip()
        ).to_dict()
        
        return vocab_dict
    except Exception as e:
        st.error(f"è¯åº“åŠ è½½å‡ºé”™: {e}")
        return None

# --- 2. ä¸‰æ®µå¼æ ¸å¿ƒé€»è¾‘ ---
def process_text_three_tiers(text, vocab_dict, range_start, range_end):
    # æ¸…æ´—æ–‡æœ¬
    text_lower = text.lower()
    words = re.findall(r'\b[a-z]{2,}\b', text_lower)
    unique_words = sorted(list(set(words)))
    
    # åˆå§‹åŒ–ä¸‰ä¸ªæ¡¶
    tier_known = []   # < Start (å·²æŒæ¡)
    tier_target = []  # Start ~ End (é‡ç‚¹çªç ´)
    tier_beyond = []  # > End (è¶…çº²)
    
    for w in unique_words:
        rank = 999999
        match_word = w
        
        # åŒ¹é…å˜ä½“ (s, ed, ing)
        if w in vocab_dict:
            rank = vocab_dict[w]
        elif w.endswith('s') and w[:-1] in vocab_dict:
            match_word = w[:-1]
            rank = vocab_dict[match_word]
        elif w.endswith('ed') and w[:-2] in vocab_dict:
            match_word = w[:-2]
            rank = vocab_dict[match_word]
        elif w.endswith('ing') and w[:-3] in vocab_dict:
            match_word = w[:-3]
            rank = vocab_dict[match_word]
            
        item = {'å•è¯ (Word)': match_word, 'æ’å (Rank)': int(rank)}
        
        # === ä¸‰çº§åˆ†æ‹£ ===
        if rank <= range_start:
            tier_known.append(item)
        elif range_start < rank <= range_end:
            tier_target.append(item)
        else:
            tier_beyond.append(item)

    # è½¬ DataFrame
    df_known = pd.DataFrame(tier_known).sort_values('æ’å (Rank)') if tier_known else pd.DataFrame()
    df_target = pd.DataFrame(tier_target).sort_values('æ’å (Rank)') if tier_target else pd.DataFrame()
    df_beyond = pd.DataFrame(tier_beyond).sort_values('æ’å (Rank)') if tier_beyond else pd.DataFrame()
        
    return df_known, df_target, df_beyond

# --- 3. ç•Œé¢ UI ---
st.title("ğŸ¯ Vibe Vocab - åˆ†çº§çªå‡»ç‰ˆ")
st.caption("è‡ªå®šä¹‰å­¦ä¹ åŒºé—´ Â· ç²¾å‡†é”å®šç›®æ ‡è¯æ±‡")

# åŠ è½½
vocab_dict = load_vocab()
if not vocab_dict:
    st.error("âŒ æ‰¾ä¸åˆ°è¯åº“æ–‡ä»¶ï¼è¯·ç¡®è®¤ GitHub ä»“åº“é‡Œæœ‰ csv æ–‡ä»¶ã€‚")
    st.stop()

# ä¾§è¾¹æ 
st.sidebar.header("âš™ï¸ å­¦ä¹ è§„åˆ’")
st.sidebar.success(f"ğŸ“š è¯åº“å·²åŠ è½½ ({len(vocab_dict)}è¯)")

# === å…³é”®æ›´æ–°ï¼šåŒæ»‘å— ===
st.sidebar.subheader("è®¾å®šä½ çš„èŒƒå›´")
# é»˜è®¤ 6000-8000
vocab_range = st.sidebar.slider(
    "æ‹–åŠ¨æ»‘å—é€‰æ‹©åŒºé—´ï¼š",
    min_value=1, 
    max_value=20000, 
    value=(6000, 8000), 
    step=500
)

range_start = vocab_range[0]
range_end = vocab_range[1]

st.sidebar.info(
    f"ğŸŸ¢ **ç†Ÿè¯**: 1 - {range_start}\n\n"
    f"ğŸŸ¡ **é‡ç‚¹**: {range_start} - {range_end}\n\n"
    f"ğŸ”´ **è¶…çº²**: {range_end}+"
)

# è¾“å…¥åŒº
with st.expander("ğŸ“ æ–‡æœ¬è¾“å…¥", expanded=True):
    tab_paste, tab_upload = st.tabs(["ç²˜è´´æ–‡æœ¬", "ä¸Šä¼  TXT"])
    with tab_paste:
        text_input = st.text_area("åœ¨æ­¤ç²˜è´´:", height=150)
    with tab_upload:
        uploaded = st.file_uploader("ä¸Šä¼ æ–‡ä»¶", type="txt")
        if uploaded:
            text_input = uploaded.read().decode("utf-8")

final_text = text_input if text_input else ""

# ç»“æœå±•ç¤ºå‡½æ•°
def show_download_buttons(df, prefix):
    if df.empty: return
    col1, col2 = st.columns(2)
    # CSV
    csv = df.to_csv(index=False).encode('utf-8')
    col1.download_button(f"ğŸ“¥ ä¸‹è½½ {prefix} Excel", csv, f"{prefix}.csv", "text/csv")
    # TXT
    txt = "\n".join(df['å•è¯ (Word)'].tolist())
    col2.download_button(f"ğŸ“„ ä¸‹è½½ {prefix} TXT", txt, f"{prefix}.txt", "text/plain")

if st.button("ğŸš€ å¼€å§‹ç²¾å‡†åˆ†æ", type="primary"):
    if not final_text.strip():
        st.warning("è¯·å…ˆè¾“å…¥æ–‡æœ¬ï¼")
    else:
        df_known, df_target, df_beyond = process_text_three_tiers(final_text, vocab_dict, range_start, range_end)
        
        st.success(f"åˆ†æå®Œæˆï¼ é‡ç‚¹ç›®æ ‡è¯æ±‡: {len(df_target)} ä¸ª")
        
        # ä¸‰ä¸ªæ ‡ç­¾é¡µ
        t1, t2, t3 = st.tabs([
            f"ğŸŸ¡ é‡ç‚¹çªç ´ ({len(df_target)})", 
            f"ğŸ”´ è¶…çº²/ç”Ÿè¯ ({len(df_beyond)})", 
            f"ğŸŸ¢ å·²æŒæ¡ ({len(df_known)})"
        ])
        
        # Tab 1: é‡ç‚¹ (æœ€é‡è¦ï¼Œæ”¾ç¬¬ä¸€ä¸ª)
        with t1:
            st.markdown(f"### ğŸ¯ ä½ çš„æ ¸å¿ƒå­¦ä¹ åŒº ({range_start}-{range_end})")
            if not df_target.empty:
                st.dataframe(df_target, use_container_width=True)
                show_download_buttons(df_target, "target_words")
            else:
                st.info("è¿™ç¯‡æ–‡ç« é‡Œæ²¡æœ‰è¿™ä¸ªèŒƒå›´çš„è¯ï¼Œå¤ªæ£’äº†ï¼ˆæˆ–è€…æ–‡ç« å¤ªç®€å•/å¤ªéš¾ï¼‰ï¼")

        # Tab 2: è¶…çº²
        with t2:
            st.markdown(f"### ğŸš€ æš‚æ—¶è·³è¿‡çš„éš¾è¯ (>{range_end})")
            if not df_beyond.empty:
                st.dataframe(df_beyond, use_container_width=True)
                show_download_buttons(df_beyond, "beyond_words")
            else:
                st.info("æ²¡æœ‰è¶…çº²è¯æ±‡ï¼")

        # Tab 3: ç†Ÿè¯
        with t3:
            st.markdown(f"### âœ… æ— éœ€å¤ä¹ çš„ç†Ÿè¯ (<{range_start})")
            if not df_known.empty:
                st.dataframe(df_known, use_container_width=True)
                show_download_buttons(df_known, "known_words")
            else:
                st.info("æ²¡æœ‰å‘ç°ç†Ÿè¯ã€‚")